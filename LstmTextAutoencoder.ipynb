{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ivy/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ivy/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils import *\n",
    "from SeqAutoencoder import * \n",
    "from LoaderData import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = r\"pascal_dataset\"\n",
    "word_description, image_description = prepare_pascal(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only one description per image\n",
    "for name, descr in word_description.items():\n",
    "    word_description[name] = descr[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_text = [item for sublist in list(word_description.values()) for item in sublist]\n",
    "#flat_text = [item for sublist in flat_text for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {'<BOS>':0, '<EOS>':1, '<UNK>':2, '<PAD>':3}\n",
    "count = 4\n",
    "for word in flat_text:\n",
    "    if word not in vocab:\n",
    "        vocab[word] = count\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = PascalLoadData(list(image_description.keys()), image_description, word_description, vocab)\n",
    "train_data_iterator = DataLoader(train_data_loader, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = OUTPUT_DIM = len(vocab)\n",
    "ENC_EMB_DIM = 64\n",
    "DEC_EMB_DIM = 64\n",
    "HID_DIM = 256\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(1402, 64)\n",
       "    (rnn): LSTM(64, 256, num_layers=2, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(1402, 64)\n",
       "    (rnn): LSTM(64, 256, num_layers=2, dropout=0.5)\n",
       "    (out): Linear(in_features=256, out_features=1402, bias=True)\n",
       "    (dropout): Dropout(p=0.5)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 2,251,898 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = vocab['<PAD>']\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, (_, descriptions) in enumerate(iterator):\n",
    "        \n",
    "        src = trg = descriptions.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg)\n",
    "        \n",
    "        #trg = [trg sent len, batch size]\n",
    "        #output = [trg sent len, batch size, output dim]\n",
    "        \n",
    "        output = output[1:].view(-1, output.shape[-1])\n",
    "        trg = trg[1:].view(-1)\n",
    "        \n",
    "        #trg = [(trg sent len - 1) * batch size]\n",
    "        #output = [(trg sent len - 1) * batch size, output dim]\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, (_, descriptions) in enumerate(iterator):\n",
    "\n",
    "            src = trg = descriptions.cuda()\n",
    "\n",
    "            output = model(src, trg, 0) #turn off teacher forcing\n",
    "\n",
    "            #trg = [trg sent len, batch size]\n",
    "            #output = [trg sent len, batch size, output dim]\n",
    "\n",
    "            output = output[1:].view(-1, output.shape[-1])\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            #trg = [(trg sent len - 1) * batch size]\n",
    "            #output = [(trg sent len - 1) * batch size, output dim]\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 4s\n",
      "\tTrain Loss: 4.398 | Train PPL:  81.327\n",
      "Epoch: 02 | Time: 0m 4s\n",
      "\tTrain Loss: 4.369 | Train PPL:  78.932\n",
      "Epoch: 03 | Time: 0m 4s\n",
      "\tTrain Loss: 4.347 | Train PPL:  77.225\n",
      "Epoch: 04 | Time: 0m 4s\n",
      "\tTrain Loss: 4.307 | Train PPL:  74.218\n",
      "Epoch: 05 | Time: 0m 4s\n",
      "\tTrain Loss: 4.272 | Train PPL:  71.635\n",
      "Epoch: 06 | Time: 0m 4s\n",
      "\tTrain Loss: 4.240 | Train PPL:  69.397\n",
      "Epoch: 07 | Time: 0m 4s\n",
      "\tTrain Loss: 4.213 | Train PPL:  67.542\n",
      "Epoch: 08 | Time: 0m 3s\n",
      "\tTrain Loss: 4.187 | Train PPL:  65.837\n",
      "Epoch: 09 | Time: 0m 3s\n",
      "\tTrain Loss: 4.155 | Train PPL:  63.722\n",
      "Epoch: 10 | Time: 0m 3s\n",
      "\tTrain Loss: 4.134 | Train PPL:  62.412\n",
      "Epoch: 11 | Time: 0m 3s\n",
      "\tTrain Loss: 4.114 | Train PPL:  61.163\n",
      "Epoch: 12 | Time: 0m 3s\n",
      "\tTrain Loss: 4.084 | Train PPL:  59.371\n",
      "Epoch: 13 | Time: 0m 4s\n",
      "\tTrain Loss: 4.069 | Train PPL:  58.490\n",
      "Epoch: 14 | Time: 0m 4s\n",
      "\tTrain Loss: 4.040 | Train PPL:  56.841\n",
      "Epoch: 15 | Time: 0m 3s\n",
      "\tTrain Loss: 4.033 | Train PPL:  56.423\n",
      "Epoch: 16 | Time: 0m 3s\n",
      "\tTrain Loss: 4.019 | Train PPL:  55.638\n",
      "Epoch: 17 | Time: 0m 3s\n",
      "\tTrain Loss: 4.004 | Train PPL:  54.810\n",
      "Epoch: 18 | Time: 0m 3s\n",
      "\tTrain Loss: 3.985 | Train PPL:  53.784\n",
      "Epoch: 19 | Time: 0m 3s\n",
      "\tTrain Loss: 3.962 | Train PPL:  52.542\n",
      "Epoch: 20 | Time: 0m 3s\n",
      "\tTrain Loss: 3.931 | Train PPL:  50.960\n",
      "Epoch: 21 | Time: 0m 3s\n",
      "\tTrain Loss: 3.910 | Train PPL:  49.910\n",
      "Epoch: 22 | Time: 0m 3s\n",
      "\tTrain Loss: 3.879 | Train PPL:  48.367\n",
      "Epoch: 23 | Time: 0m 3s\n",
      "\tTrain Loss: 3.844 | Train PPL:  46.727\n",
      "Epoch: 24 | Time: 0m 3s\n",
      "\tTrain Loss: 3.827 | Train PPL:  45.913\n",
      "Epoch: 25 | Time: 0m 3s\n",
      "\tTrain Loss: 3.803 | Train PPL:  44.817\n",
      "Epoch: 26 | Time: 0m 3s\n",
      "\tTrain Loss: 3.784 | Train PPL:  43.985\n",
      "Epoch: 27 | Time: 0m 3s\n",
      "\tTrain Loss: 3.752 | Train PPL:  42.626\n",
      "Epoch: 28 | Time: 0m 3s\n",
      "\tTrain Loss: 3.742 | Train PPL:  42.184\n",
      "Epoch: 29 | Time: 0m 3s\n",
      "\tTrain Loss: 3.740 | Train PPL:  42.089\n",
      "Epoch: 30 | Time: 0m 3s\n",
      "\tTrain Loss: 3.718 | Train PPL:  41.187\n",
      "Epoch: 31 | Time: 0m 3s\n",
      "\tTrain Loss: 3.716 | Train PPL:  41.108\n",
      "Epoch: 32 | Time: 0m 3s\n",
      "\tTrain Loss: 3.684 | Train PPL:  39.817\n",
      "Epoch: 33 | Time: 0m 3s\n",
      "\tTrain Loss: 3.678 | Train PPL:  39.555\n",
      "Epoch: 34 | Time: 0m 3s\n",
      "\tTrain Loss: 3.669 | Train PPL:  39.219\n",
      "Epoch: 35 | Time: 0m 3s\n",
      "\tTrain Loss: 3.658 | Train PPL:  38.803\n",
      "Epoch: 36 | Time: 0m 3s\n",
      "\tTrain Loss: 3.640 | Train PPL:  38.108\n",
      "Epoch: 37 | Time: 0m 3s\n",
      "\tTrain Loss: 3.651 | Train PPL:  38.523\n",
      "Epoch: 38 | Time: 0m 3s\n",
      "\tTrain Loss: 3.625 | Train PPL:  37.512\n",
      "Epoch: 39 | Time: 0m 3s\n",
      "\tTrain Loss: 3.603 | Train PPL:  36.718\n",
      "Epoch: 40 | Time: 0m 3s\n",
      "\tTrain Loss: 3.585 | Train PPL:  36.069\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 40\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_data_iterator, optimizer, criterion, CLIP)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
